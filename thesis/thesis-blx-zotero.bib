
@misc{isensee_nnu-net_2018,
	title = {{nnU}-Net: Self-adapting Framework for U-Net-Based Medical Image Segmentation},
	url = {http://arxiv.org/abs/1809.10486},
	doi = {10.48550/arXiv.1809.10486},
	shorttitle = {{nnU}-Net},
	abstract = {The U-Net was presented in 2015. With its straight-forward and successful architecture it quickly evolved to a commonly used benchmark in medical image segmentation. The adaptation of the U-Net to novel problems, however, comprises several degrees of freedom regarding the exact architecture, preprocessing, training and inference. These choices are not independent of each other and substantially impact the overall performance. The present paper introduces the {nnU}-Net ('no-new-Net'), which refers to a robust and self-adapting framework on the basis of 2D and 3D vanilla U-Nets. We argue the strong case for taking away superfluous bells and whistles of many proposed network designs and instead focus on the remaining aspects that make out the performance and generalizability of a method. We evaluate the {nnU}-Net in the context of the Medical Segmentation Decathlon challenge, which measures segmentation performance in ten disciplines comprising distinct entities, image modalities, image geometries and dataset sizes, with no manual adjustments between datasets allowed. At the time of manuscript submission, {nnU}-Net achieves the highest mean dice scores across all classes and seven phase 1 tasks (except class 1 in {BrainTumour}) in the online leaderboard of the challenge.},
	number = {{arXiv}:1809.10486},
	publisher = {{arXiv}},
	author = {Isensee, Fabian and Petersen, Jens and Klein, Andre and Zimmerer, David and Jaeger, Paul F. and Kohl, Simon and Wasserthal, Jakob and Koehler, Gregor and Norajitra, Tobias and Wirkert, Sebastian and Maier-Hein, Klaus H.},
	urldate = {2023-08-09},
	date = {2018-09-27},
	eprinttype = {arxiv},
	eprint = {1809.10486 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/janiswehen/Zotero/storage/6S7GBYSN/Isensee et al. - 2018 - nnU-Net Self-adapting Framework for U-Net-Based M.pdf:application/pdf;arXiv.org Snapshot:/Users/janiswehen/Zotero/storage/QYNVPSUJ/1809.html:text/html},
}

@misc{simpson_large_2019,
	title = {A large annotated medical image dataset for the development and evaluation of segmentation algorithms},
	url = {http://arxiv.org/abs/1902.09063},
	abstract = {Semantic segmentation of medical images aims to associate a pixel with a label in a medical image without human initialization. The success of semantic segmentation algorithms is contingent on the availability of high-quality imaging data with corresponding labels provided by experts. We sought to create a large collection of annotated medical image datasets of various clinically relevant anatomies available under open source license to facilitate the development of semantic segmentation algorithms. Such a resource would allow: 1) objective assessment of general-purpose segmentation methods through comprehensive benchmarking and 2) open and free access to medical image data for any researcher interested in the problem domain. Through a multi-institutional effort, we generated a large, curated dataset representative of several highly variable segmentation tasks that was used in a crowd-sourced challenge - the Medical Segmentation Decathlon held during the 2018 Medical Image Computing and Computer Aided Interventions Conference in Granada, Spain. Here, we describe these ten labeled image datasets so that these data may be effectively reused by the research community.},
	number = {{arXiv}:1902.09063},
	publisher = {{arXiv}},
	author = {Simpson, Amber L. and Antonelli, Michela and Bakas, Spyridon and Bilello, Michel and Farahani, Keyvan and van Ginneken, Bram and Kopp-Schneider, Annette and Landman, Bennett A. and Litjens, Geert and Menze, Bjoern and Ronneberger, Olaf and Summers, Ronald M. and Bilic, Patrick and Christ, Patrick F. and Do, Richard K. G. and Gollub, Marc and Golia-Pernicka, Jennifer and Heckers, Stephan H. and Jarnagin, William R. and {McHugo}, Maureen K. and Napel, Sandy and Vorontsov, Eugene and Maier-Hein, Lena and Cardoso, M. Jorge},
	urldate = {2023-08-09},
	date = {2019-02-24},
	eprinttype = {arxiv},
	eprint = {1902.09063 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {arXiv Fulltext PDF:/Users/janiswehen/Zotero/storage/WX5AH5GP/Simpson et al. - 2019 - A large annotated medical image dataset for the de.pdf:application/pdf;arXiv.org Snapshot:/Users/janiswehen/Zotero/storage/SYXY9J69/1902.html:text/html},
}

@misc{ronneberger_u-net_2015,
	title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
	url = {http://arxiv.org/abs/1505.04597},
	doi = {10.48550/arXiv.1505.04597},
	shorttitle = {U-Net},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the {ISBI} challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and {DIC}) we won the {ISBI} cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent {GPU}. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
	number = {{arXiv}:1505.04597},
	publisher = {{arXiv}},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	urldate = {2023-08-15},
	date = {2015-05-18},
	eprinttype = {arxiv},
	eprint = {1505.04597 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/janiswehen/Zotero/storage/RKK2XTKV/Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image.pdf:application/pdf;arXiv.org Snapshot:/Users/janiswehen/Zotero/storage/ZNEKD5ML/1505.html:text/html},
}

@misc{oshea_introduction_2015,
	title = {An Introduction to Convolutional Neural Networks},
	url = {http://arxiv.org/abs/1511.08458},
	doi = {10.48550/arXiv.1511.08458},
	abstract = {The field of machine learning has taken a dramatic twist in recent times, with the rise of the Artificial Neural Network ({ANN}). These biologically inspired computational models are able to far exceed the performance of previous forms of artificial intelligence in common machine learning tasks. One of the most impressive forms of {ANN} architecture is that of the Convolutional Neural Network ({CNN}). {CNNs} are primarily used to solve difficult image-driven pattern recognition tasks and with their precise yet simple architecture, offers a simplified method of getting started with {ANNs}. This document provides a brief introduction to {CNNs}, discussing recently published papers and newly formed techniques in developing these brilliantly fantastic image recognition models. This introduction assumes you are familiar with the fundamentals of {ANNs} and machine learning.},
	number = {{arXiv}:1511.08458},
	publisher = {{arXiv}},
	author = {O'Shea, Keiron and Nash, Ryan},
	urldate = {2023-08-18},
	date = {2015-12-02},
	eprinttype = {arxiv},
	eprint = {1511.08458 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:/Users/janiswehen/Zotero/storage/32NAVFER/O'Shea und Nash - 2015 - An Introduction to Convolutional Neural Networks.pdf:application/pdf;arXiv.org Snapshot:/Users/janiswehen/Zotero/storage/WZLR8DQT/1511.html:text/html},
}

@misc{ioffe_batch_2015,
	title = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
	url = {http://arxiv.org/abs/1502.03167},
	doi = {10.48550/arXiv.1502.03167},
	shorttitle = {Batch Normalization},
	abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on {ImageNet} classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.},
	number = {{arXiv}:1502.03167},
	publisher = {{arXiv}},
	author = {Ioffe, Sergey and Szegedy, Christian},
	urldate = {2023-08-19},
	date = {2015-03-02},
	eprinttype = {arxiv},
	eprint = {1502.03167 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/janiswehen/Zotero/storage/9CGFM3X8/Ioffe und Szegedy - 2015 - Batch Normalization Accelerating Deep Network Tra.pdf:application/pdf;arXiv.org Snapshot:/Users/janiswehen/Zotero/storage/NP4ENB5M/1502.html:text/html},
}

@misc{kingma_adam_2017,
	title = {Adam: A Method for Stochastic Optimization},
	url = {http://arxiv.org/abs/1412.6980},
	doi = {10.48550/arXiv.1412.6980},
	shorttitle = {Adam},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss {AdaMax}, a variant of Adam based on the infinity norm.},
	number = {{arXiv}:1412.6980},
	publisher = {{arXiv}},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	urldate = {2023-08-19},
	date = {2017-01-29},
	eprinttype = {arxiv},
	eprint = {1412.6980 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/janiswehen/Zotero/storage/M6VQVRXT/Kingma und Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:application/pdf;arXiv.org Snapshot:/Users/janiswehen/Zotero/storage/66MU6NX5/1412.html:text/html},
}

@misc{wang_super-resolution_2023,
	title = {Super-Resolution Based Patch-Free 3D Image Segmentation with High-Frequency Guidance},
	url = {http://arxiv.org/abs/2210.14645},
	abstract = {High resolution ({HR}) 3D images are widely used nowadays, such as medical images like Magnetic Resonance Imaging ({MRI}) and Computed Tomography ({CT}). However, segmentation of these 3D images remains a challenge due to their high spatial resolution and dimensionality in contrast to currently limited {GPU} memory. Therefore, most existing 3D image segmentation methods use patch-based models, which have low inference efficiency and ignore global contextual information. To address these problems, we propose a super-resolution ({SR}) based patch-free 3D image segmentation framework that can realize {HR} segmentation from a global-wise low-resolution ({LR}) input. The framework contains two sub-tasks, of which semantic segmentation is the main task and super resolution is an auxiliary task aiding in rebuilding the high frequency information from the {LR} input. To furthermore balance the information loss with the {LR} input, we propose a High-Frequency Guidance Module ({HGM}), and design an efficient selective cropping algorithm to crop an {HR} patch from the original image as restoration guidance for it. In addition, we also propose a Task-Fusion Module ({TFM}) to exploit the inter connections between segmentation and {SR} task, realizing joint optimization of the two tasks. When predicting, only the main segmentation task is needed, while other modules can be removed for acceleration. The experimental results on two different datasets show that our framework has a four times higher inference speed compared to traditional patch-based methods, while its performance also surpasses other patch-based and patch-free models.},
	number = {{arXiv}:2210.14645},
	publisher = {{arXiv}},
	author = {Wang, Hongyi and Lin, Lanfen and Hu, Hongjie and Chen, Qingqing and Li, Yinhao and Iwamoto, Yutaro and Han, Xian-Hua and Chen, Yen-Wei and Tong, Ruofeng},
	urldate = {2023-08-22},
	date = {2023-07-10},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2210.14645 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {Wang et al. - 2023 - Super-Resolution Based Patch-Free 3D Image Segment.pdf:/Users/janiswehen/Zotero/storage/LNYLV3GB/Wang et al. - 2023 - Super-Resolution Based Patch-Free 3D Image Segment.pdf:application/pdf},
}

@article{zhou_review_2021,
	title = {A review of deep learning in medical imaging: Imaging traits, technology trends, case studies with progress highlights, and future promises},
	volume = {109},
	issn = {0018-9219, 1558-2256},
	url = {http://arxiv.org/abs/2008.09104},
	doi = {10.1109/JPROC.2021.3054390},
	shorttitle = {A review of deep learning in medical imaging},
	abstract = {Since its renaissance, deep learning has been widely used in various medical imaging tasks and has achieved remarkable success in many medical imaging applications, thereby propelling us into the so-called artiﬁcial intelligence ({AI}) era. It is known that the success of {AI} is mostly attributed to the availability of big data with annotations for a single task and the advances in high performance computing. However, medical imaging presents unique challenges that confront deep learning approaches. In this survey paper, we ﬁrst present traits of medical imaging, highlight both clinical needs and technical challenges in medical imaging, and describe how emerging trends in deep learning are addressing these issues. We cover the topics of network architecture, sparse and noisy labels, federating learning, interpretability, uncertainty quantiﬁcation, etc. Then, we present several case studies that are commonly found in clinical practice, including digital pathology and chest, brain, cardiovascular, and abdominal imaging. Rather than presenting an exhaustive literature survey, we instead describe some prominent research highlights related to these case study applications. We conclude with a discussion and presentation of promising future directions.},
	pages = {820--838},
	number = {5},
	journaltitle = {Proceedings of the {IEEE}},
	shortjournal = {Proc. {IEEE}},
	author = {Zhou, S. Kevin and Greenspan, Hayit and Davatzikos, Christos and Duncan, James S. and van Ginneken, Bram and Madabhushi, Anant and Prince, Jerry L. and Rueckert, Daniel and Summers, Ronald M.},
	urldate = {2023-08-22},
	date = {2021-05},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2008.09104 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {Zhou et al. - 2021 - A review of deep learning in medical imaging Imag.pdf:/Users/janiswehen/Zotero/storage/9YCGFPZT/Zhou et al. - 2021 - A review of deep learning in medical imaging Imag.pdf:application/pdf},
}
